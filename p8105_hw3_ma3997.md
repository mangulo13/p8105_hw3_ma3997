Homework 3 solutions
================
Matthew Angulo
October 10, 2020

## Problem 1

``` r
data("instacart") 
```

This dataset contains 1384617 rows and 15 columns

Observations are at the level of items in orders by user. There are user
/ order variables – user ID, order ID, order day, and order hour. There
are also item variables – name, aisle, department, and some numeric
codes.

How many aisles, and which are most items from?

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # ... with 124 more rows

Let’s make a plot

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n >10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n))+
  geom_point()+
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))
```

<img src="p8105_hw3_ma3997_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

Let’s make a table\!

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, desc(n)) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Apples vs ice cream

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Question 2

``` r
accel_df = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
  )) %>% 
  arrange(day, week) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>% 
  mutate(
    weekday_weekend = case_when(
      day %in% c("Saturday", "Sunday") ~ "weekend",
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      TRUE ~ "")
  ) %>% 
  mutate(
     weekday_weekend = factor(weekday_weekend),
     minute = as.numeric(minute)
  ) %>% 
  relocate(week, day_id, day, weekday_weekend)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

``` r
accel_df
```

    ## # A tibble: 50,400 x 6
    ##     week day_id day    weekday_weekend minute activity_count
    ##    <dbl>  <dbl> <fct>  <fct>            <dbl>          <dbl>
    ##  1     1      2 Monday weekday              1              1
    ##  2     1      2 Monday weekday              2              1
    ##  3     1      2 Monday weekday              3              1
    ##  4     1      2 Monday weekday              4              1
    ##  5     1      2 Monday weekday              5              1
    ##  6     1      2 Monday weekday              6              1
    ##  7     1      2 Monday weekday              7              1
    ##  8     1      2 Monday weekday              8              1
    ##  9     1      2 Monday weekday              9              1
    ## 10     1      2 Monday weekday             10              1
    ## # ... with 50,390 more rows

This dataset contains the amount of activity one subject exerted over a
number of days. The accel\_df has 6 variables that include day, whether
it was the weekend or not, the minute of the day, and the amount of
activity recorded. In this dataset, there were50400 observations - one
for each second of the day for 35 days.

``` r
accel_df %>% 
  group_by(week, day) %>% 
  summarize(total = sum(activity_count)) %>% 
  knitr::kable()
```

    ## `summarise()` regrouping output by 'week' (override with `.groups` argument)

| week | day       |     total |
| ---: | :-------- | --------: |
|    1 | Monday    |  78828.07 |
|    1 | Tuesday   | 307094.24 |
|    1 | Wednesday | 340115.01 |
|    1 | Thursday  | 355923.64 |
|    1 | Friday    | 480542.62 |
|    1 | Saturday  | 376254.00 |
|    1 | Sunday    | 631105.00 |
|    2 | Monday    | 295431.00 |
|    2 | Tuesday   | 423245.00 |
|    2 | Wednesday | 440962.00 |
|    2 | Thursday  | 474048.00 |
|    2 | Friday    | 568839.00 |
|    2 | Saturday  | 607175.00 |
|    2 | Sunday    | 422018.00 |
|    3 | Monday    | 685910.00 |
|    3 | Tuesday   | 381507.00 |
|    3 | Wednesday | 468869.00 |
|    3 | Thursday  | 371230.00 |
|    3 | Friday    | 467420.00 |
|    3 | Saturday  | 382928.00 |
|    3 | Sunday    | 467052.00 |
|    4 | Monday    | 409450.00 |
|    4 | Tuesday   | 319568.00 |
|    4 | Wednesday | 434460.00 |
|    4 | Thursday  | 340291.00 |
|    4 | Friday    | 154049.00 |
|    4 | Saturday  |   1440.00 |
|    4 | Sunday    | 260617.00 |
|    5 | Monday    | 389080.00 |
|    5 | Tuesday   | 367824.00 |
|    5 | Wednesday | 445366.00 |
|    5 | Thursday  | 549658.00 |
|    5 | Friday    | 620860.00 |
|    5 | Saturday  |   1440.00 |
|    5 | Sunday    | 138421.00 |

Analyzing the total activity count for the 35 days shows that there are
several outliers. On two Saturdays, the subject recorded the baseline
amount of activity. The first Monday of the trial also recorded a very
low amount of activity.

``` r
accel_df %>% 
  ggplot(aes(x = minute, y =activity_count, color = day))+
  geom_line(alpha = .7)
```

<img src="p8105_hw3_ma3997_files/figure-gfm/part 2.3-1.png" width="90%" />

The subject recorded little activity between 10:00AM (or \~600 minutes)
and 6:30PM (or \~1100 minutes). The subject did have a frequent high
peak during the work week around 9pm. Sundays the subject exerted more
activity during the middle fo the day in comparison to other days.

## Question 3

``` r
library(p8105.datasets)
library(hexbin)
library(ggridges)
library(patchwork)
data("ny_noaa")
```

``` r
ny_noaa_df = 
  ny_noaa %>% 
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(
    tmin = as.numeric(tmin),
    tmax = as.numeric(tmax),
    prcp = prcp * 0.1,
    tmax = tmax * 0.1,
    tmin = tmin * 0.1
    )

count(ny_noaa_df, snow) %>% 
  arrange(-n)
```

    ## # A tibble: 282 x 2
    ##     snow       n
    ##    <int>   <int>
    ##  1     0 2008508
    ##  2    NA  381221
    ##  3    25   31022
    ##  4    13   23095
    ##  5    51   18274
    ##  6    76   10173
    ##  7     8    9962
    ##  8     5    9748
    ##  9    38    9197
    ## 10     3    8790
    ## # ... with 272 more rows

This is a large dataset that has 2595176 observations and 9 variables
including: weather station, day, month, year, min and max temperature,
amount of rainfall, amount of snowfall, and snow density. There are
numerous stations that are missing records on precipitation,
temperature, and snowfall throughout the years. Precipation values were
converted to mm from tenths of

The most common amount of reported snowfall was either 0mm or NA.
Certainly the expected distribution since the NY regions experiences
more days without snowfall than days with it.

``` r
panel_df= 
  ny_noaa_df %>% 
  filter(month %in% c("1","7")) %>% 
  group_by(year, month, id) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id))+
  geom_point(alpha = .5)+
  geom_path()+
  facet_grid(. ~ month)+
  labs(title = "Mean max temperature for January and July across stations and years", x = "year", y = "average maximum temperature (C)")+
  theme(legend.position = "none", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

    ## `summarise()` regrouping output by 'year', 'month' (override with `.groups` argument)

``` r
panel_df
```

    ## Warning: Removed 5970 rows containing missing values (geom_point).

    ## Warning: Removed 5931 row(s) containing missing values (geom_path).

<img src="p8105_hw3_ma3997_files/figure-gfm/part 3.2-1.png" width="90%" />

The mean maximum temperature among these weather stations shows that
January 1994 and 2004 were particularly cold winters. However, the max
temperatures in January at these weather stations seems to be trending
warmer.

The July 2010 max temperatures were some of the highest recorded for
that month since this dataset first started recording.

``` r
hex_panel_df = 
  ny_noaa_df %>% 
  ggplot(aes(x = tmin, y = tmax))+
  geom_hex()+
  labs(title = "Daily max temperatures versus daily min temperatures")+
  guides(fill = guide_colorbar(barwidth = 12))+
  theme(plot.title = element_text(hjust = 0.5))

hex_panel_df
```

    ## Warning: Removed 1136276 rows containing non-finite values (stat_binhex).

<img src="p8105_hw3_ma3997_files/figure-gfm/part 3.3-1.png" width="90%" />

``` r
box_panel_df =
  ny_noaa_df %>% 
  filter(snow %in% c(1:99)) %>% 
  ggplot(aes( x = snow, y = year, group = year))+
  geom_boxplot()+
  theme(legend.position = "none", plot.title = element_text(hjust = 0.5))+
  labs(title = "Yearly amount of snowfall")

box_panel_df
```

<img src="p8105_hw3_ma3997_files/figure-gfm/part 3.3-2.png" width="90%" />

``` r
hex_panel_df + box_panel_df
```

    ## Warning: Removed 1136276 rows containing non-finite values (stat_binhex).

<img src="p8105_hw3_ma3997_files/figure-gfm/part 3.3-3.png" width="90%" />
