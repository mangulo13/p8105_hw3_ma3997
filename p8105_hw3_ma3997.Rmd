---
title: "Homework 3 solutions"
author: "Matthew Angulo"
date: "October 10, 2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)


theme_set(theme_minimal()+theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colur = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

```


## Problem 1

```{r}
data("instacart") 
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns 

Observations are at the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```


Let's make a plot 

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n >10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n))+
  geom_point()+
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))
```

Let's make a table!

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, desc(n)) %>% 
  knitr::kable()
```


Apples vs ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
  

```


## Question 2

```{r part 2.1}
accel_df = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
  )) %>% 
  arrange(day, week) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity_count"
  ) %>% 
  mutate(
    weekday_weekend = case_when(
      day %in% c("Saturday", "Sunday") ~ "weekend",
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") ~ "weekday",
      TRUE ~ "")
  ) %>% 
  mutate(
     weekday_weekend = factor(weekday_weekend),
     minute = as.numeric(minute)
  ) %>% 
  relocate(week, day_id, day, weekday_weekend)

accel_df
```

This dataset 


Pivot longer, havnig something for activity count and minute, add variable with mutate, reasonable order and names, 

```{r part 2.2}
accel_df %>% 
  group_by(week, day) %>% 
  summarize(total = sum(activity_count)) %>% 
  knitr::kable()
```


Aggregrate with group by week and then day and summarize with mean or sum to end up with table with 35 days and activity count for each of those days. Make table easier to read with week number and day of the week. Trends apparent that just point out busy weeks or slow weeks Day of the week is gonna be in alpha order so need to use factors to reorder


```{r part 2.3}
accel_df %>% 
  ggplot(aes(x = minute, y =activity_count, color = day))+
  geom_line()
```

Little activity during 500 - 1200 minutes especially during work week

Make a plot. Want to see activity at each minute of each day. Minute on x and activity count on y. Scatterplot wont work. geom_line is a little bit better. Aesthetic mapping for color = day of week. Is minute of the day a numeric or factor or character?  

## Question 3

```{r part 3.1}
library(p8105.datasets)
library(hexbin)
data("ny_noaa")

ny_noaa_df = 
  ny_noaa %>% 
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
  mutate(
    tmin = as.numeric(tmin),
    tmax = as.numeric(tmax),
    prcp = prcp * 0.01,
    tmin = tmin * 0.01,
    tmax = tmax * 0.01
  )

count(ny_noaa_df, snow)
  

  
```

Separate y-m-d into year and month and day variables. Convert prcp and snowfall to an easier to comprehend value range. use count to find most common 


```{r part 3.2}
panel_df= 
  ny_noaa_df %>% 
  filter(month %in% c("1","7")) %>% 
  group_by(year, month, id) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id))+
  geom_point(alpha = .5)+
  geom_path()+
  facet_grid(. ~ month)+
  labs(title = "Mean temperature for January and July across stations and years", x = "year", y = "average maximum temperature (C)")+
  theme(legend.position = "none", axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

panel_df
```


Group by station, year, and month and summarize to get max temp. Filter at some point, either way it will wrok Plot. Facet to get two panels

```{r part 3.3}

```

use patchwork to combine plots. First one could be hex plot or contour plot instead of scatterplot. For second filter first, and then use boxplot, ridge plot, violin plot 


